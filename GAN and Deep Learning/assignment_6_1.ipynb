{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MS5Lireo7Ju"
   },
   "source": [
    "# **1. Generative Models for Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JsgNU3pERizS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.color import rgb2gray\n",
    "#import cv2\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, BatchNormalization, Activation, Dropout,LeakyReLU, add, MaxPooling2D,LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam,SGD\n",
    "opt = Adam(lr=0.1)\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmdCwkcppLz9"
   },
   "source": [
    "**(b) Download the following books from Project Gutenberg http://www.gutenberg. org/ebooks/author/355 in text format:\n",
    "i. The Problems of Philosophy\n",
    "ii. The Analysis of Mind\n",
    "iii. Mysticism and Logic and Other Essays\n",
    "iv. Our Knowledge of the External World as a Field for Scientific Method in Philosophy\n",
    "Project Gutenberg adds a standard header and footer to each book and this is not part of the original text. Open the file in a text editor and delete the header and footer.\n",
    "The header is obvious and ends with the text:\n",
    "*** START OF THIS PROJECT GUTENBERG EBOOK AN INQUIRY INTO MEANING AND TRUTH ***\n",
    "The footer is all of the text after the line of text that says:\n",
    "THE END\n",
    "To have a better model, it is strongly recommended that you download the fol- lowing books from The Library of Congress https://archive.org and convert them to text files:\n",
    "i. The History of Western Philosophy\n",
    "             https://archive.org/details/westernphilosophy4\n",
    "ii. The Analysis of Matter\n",
    "             https://archive.org/details/in.ernet.dli.2015.221533\n",
    "iii. An Inquiry into Meaning and Truth\n",
    "            https://archive.org/details/BertrandRussell-AnInquaryIntoMeaningAndTruth\n",
    "Try to only use the text of the books and throw away unwanted text before and after the text, although in a large corpus, these are considered as noise and should not make big problems.1 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "u_iNpoaqfzKz"
   },
   "outputs": [],
   "source": [
    "filenames=os.listdir('drive/assgn-6')\n",
    "#filenames=filenames.remove('.Trash')\n",
    "filenames=['drive/assgn-6/'+i for i in filenames]\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UIakem3ERzdR"
   },
   "outputs": [],
   "source": [
    "with open('drive/final.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IbozxmJgUtf6"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "line = re.sub('[!@#$]', '', line)\n",
    "f=open('drive/final.txt','r')\n",
    "x=f.read().lower()\n",
    "chars = sorted(list(set(x))) \n",
    "yo=['\\n',' ',',','.','0', '1', '2', '3', '4', '5', '6', '7', '8' ,'9','a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "chars1=chars\n",
    "for i in yo:\n",
    "  chars1.remove(i)\n",
    "for i in chars1:\n",
    "  x=x.replace(i,\"\")\n",
    "x1=str()\n",
    "for i in chars1:\n",
    "  x1=x1+i  \n",
    "x = re.sub('[)+/;>[_| ·æéîôüŭβηιλορτὴίό″]', '', x)\n",
    "x=x.replace(\"\\n\",\" \")\n",
    "#chars.remove(\"\\n\")\n",
    "x=' '.join(x.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOdqUYAvX7TX"
   },
   "source": [
    "### **Answer**:All the text files were inserted into a directory from which they were concatenated to a single file called 'final'. Only letters of alphabet and spaces with comma and period were kept as characters. New line was also removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRZyegnppa96"
   },
   "source": [
    "## c) LSTM: Train an LSTM to mimic Russell’s style and thoughts:\n",
    "## i. Concatenate your text files to create a corpus of Russell’s writings.\n",
    "## ii. Use a character-level representation for this model by using extended ASCII that has N = 256 characters. Each character will be encoded into a an integer using its ASCII code. Rescale the integers to the range [0, 1], because LSTM uses a sigmoid activation function. LSTM will receive the rescaled integers as its input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sfiPxFcU36np"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(x))) \n",
    "with open('drive/final1.txt', 'w') as outfile:\n",
    "    outfile.write(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6shyhENApnEP"
   },
   "source": [
    "## iii) Choose a window size, e.g., W = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYaveDKoqjtm"
   },
   "source": [
    "## iv)Inputs to the network will be the first W −1 = 99 characters of each sequence, and the output of the network will be the Lth character of the sequence. Basically, we are training the network to predict the each character using the 99 characters that precede it. Slide the window in strides of S = 1 on the text. For example, if W = 5 and S = 1 and we want to train the network with the sequence ABRACADABRA, The first input to the network will be ABRA and the corresponding output will be C. The second input will be BRAC and the second output will be A, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "3k1Sm5AdgRuS"
   },
   "outputs": [],
   "source": [
    "with open('drive/final1.txt', 'r') as file:\n",
    "    x=file.read()\n",
    "x=x[:int(len(x))]    \n",
    "unique_chars = sorted(list(set(x))) \n",
    "char_ascii = dict((c, i) for i, c in enumerate(unique_chars))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "j8_4Ola_ZyYW"
   },
   "outputs": [],
   "source": [
    "n_chars = len(x)\n",
    "n_vocab = len(unique_chars)\n",
    "window = 99\n",
    "input_seq = []\n",
    "output_seq = []\n",
    "for i in range(0, n_chars - window,1):\n",
    "    input1 = x[i:i + window]\n",
    "    output1 =x[i+window]\n",
    "    input_seq.append([char_ascii[char] for char in input1])\n",
    "    output_seq.append(char_ascii[output1])\n",
    "n_patterns = len(input_seq)\n",
    "X = np.reshape(input_seq, (n_patterns, window, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Vj6nVHlnZ3gm"
   },
   "outputs": [],
   "source": [
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuZCsVtAY1Fl"
   },
   "source": [
    "Answer: Sequences of length 99 were created and output is of length 1. All these sequences then act as input to the LSTM. \n",
    "Also, the input characters were rescaled between [0,1] to make use of sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGRUVyzNaESP"
   },
   "source": [
    "## v)Note that the output has to be encoded using a one-hot encoding scheme with N = 256 (or less) elements. This means that the network reads integers, but outputs a vector of N = 256 (or less) elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CA4RWZ0Z2YO"
   },
   "source": [
    "Also, the final output is one-hot encoded to make use of softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ySNuRFJ1gclD"
   },
   "outputs": [],
   "source": [
    "output_seq=np.array(output_seq)\n",
    "y = np_utils.to_categorical(output_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iw-rxP6Wq3Q4"
   },
   "source": [
    "\n",
    "## vi)Use a single hidden layer for the LSTM with N = 256 (or less) memory units.\n",
    "## vii)Use a Softmax output layer to yield a probability prediction for each of the characters between 0 and 1. This is actually a character classification problem with N classes. Choose log loss (cross entropy) as the objective function for the network (research what it menas).3\n",
    "## viii)We do not use a test dataset. We are using the whole training dataset to learn the probability of each character in a sequence. We are not seeking for a very accurate model of. Instead we are interested in a generalization of the dataset that can mimic the gist of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "PyS49dh03ZCJ"
   },
   "outputs": [],
   "source": [
    "reverse_map = dict((i, c) for i, c in enumerate(unique_chars))\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X.shape[1], X.shape[2]), activation='sigmoid',return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.load_weights(\"drive/weights-improvement-10-2.1577-bigger.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOa8WEw6a2mf"
   },
   "source": [
    "#### Answer: I used a single hidden layer. The categorical cross-entropy was used.\n",
    "#### The cross entropy between two probability distributions  p and  q over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an \"unnatural\" probability distribution  q, rather than the \"true\" distribution  p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cZD1EZ4rKDj"
   },
   "source": [
    "## ix)Choose a reasonable number of epochs for training (e.g., 30, although the network will need more epochs to yield a better model).\n",
    "## x)Use model checkpointing to keep the network weights to determine each time an improvement in loss is observed at the end of the epoch. Find the best set of weights in terms of loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lc1Iu9OfaN8H"
   },
   "source": [
    "#### Answer : At the end of each epoch we store the best set of weights with ModelCheckpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wY8tzyn1lQ3Q"
   },
   "outputs": [],
   "source": [
    "filepath=\"drive/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23950114,
     "status": "ok",
     "timestamp": 1525267846179,
     "user": {
      "displayName": "Dab Berman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117214817576741121998"
     },
     "user_tz": 420
    },
    "id": "meWnhC6yzHPx",
    "outputId": "ed0c4e58-c500-4d11-944a-79b1b05e4670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1320348/1320348 [==============================] - 2427s 2ms/step - loss: 2.3090\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.30896, saving model to drive/weights-improvement-01-2.3090-bigger.hdf5\n",
      "Epoch 2/10\n",
      " 127488/1320348 [=>............................] - ETA: 36:36 - loss: 2.28471320348/1320348 [==============================] - 2431s 2ms/step - loss: 2.2825\n",
      "\n",
      "Epoch 00002: loss improved from 2.30896 to 2.28254, saving model to drive/weights-improvement-02-2.2825-bigger.hdf5\n",
      "Epoch 3/10\n",
      " 124928/1320348 [=>............................] - ETA: 36:47 - loss: 2.26801320348/1320348 [==============================] - 2429s 2ms/step - loss: 2.2609\n",
      "\n",
      "Epoch 00003: loss improved from 2.28254 to 2.26091, saving model to drive/weights-improvement-03-2.2609-bigger.hdf5\n",
      "Epoch 4/10\n",
      " 124928/1320348 [=>............................] - ETA: 36:26 - loss: 2.25001320348/1320348 [==============================] - 2420s 2ms/step - loss: 2.2406\n",
      "\n",
      "Epoch 00004: loss improved from 2.26091 to 2.24055, saving model to drive/weights-improvement-04-2.2406-bigger.hdf5\n",
      "Epoch 5/10\n",
      " 124928/1320348 [=>............................] - ETA: 36:27 - loss: 2.23161320348/1320348 [==============================] - 2386s 2ms/step - loss: 2.2238\n",
      "\n",
      "Epoch 00005: loss improved from 2.24055 to 2.22376, saving model to drive/weights-improvement-05-2.2238-bigger.hdf5\n",
      "Epoch 6/10\n",
      " 124928/1320348 [=>............................] - ETA: 35:51 - loss: 2.21441320348/1320348 [==============================] - 2375s 2ms/step - loss: 2.2082\n",
      "\n",
      "Epoch 00006: loss improved from 2.22376 to 2.20817, saving model to drive/weights-improvement-06-2.2082-bigger.hdf5\n",
      "Epoch 7/10\n",
      " 124928/1320348 [=>............................] - ETA: 35:46 - loss: 2.20081320348/1320348 [==============================] - 2366s 2ms/step - loss: 2.1941\n",
      "\n",
      "Epoch 00007: loss improved from 2.20817 to 2.19407, saving model to drive/weights-improvement-07-2.1941-bigger.hdf5\n",
      "Epoch 8/10\n",
      " 124928/1320348 [=>............................] - ETA: 35:32 - loss: 2.17951320348/1320348 [==============================] - 2363s 2ms/step - loss: 2.1798\n",
      "\n",
      "Epoch 00008: loss improved from 2.19407 to 2.17979, saving model to drive/weights-improvement-08-2.1798-bigger.hdf5\n",
      "Epoch 9/10\n",
      " 124928/1320348 [=>............................] - ETA: 35:28 - loss: 2.16641320348/1320348 [==============================] - 2366s 2ms/step - loss: 2.1689\n",
      "\n",
      "Epoch 00009: loss improved from 2.17979 to 2.16890, saving model to drive/weights-improvement-09-2.1689-bigger.hdf5\n",
      "Epoch 10/10\n",
      " 124416/1320348 [=>............................] - ETA: 35:38 - loss: 2.16111320348/1320348 [==============================] - 2360s 2ms/step - loss: 2.1577\n",
      "\n",
      "Epoch 00010: loss improved from 2.16890 to 2.15766, saving model to drive/weights-improvement-10-2.1577-bigger.hdf5\n"
     ]
    }
   ],
   "source": [
    "model.fit(X,y,epochs=10,batch_size=256,callbacks=callbacks_list)\n",
    "model.save_weights(\"drive/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMx3lMQ0fIfd"
   },
   "source": [
    "#### Answer: The model was run for approximately 26 epochs . The runtime was significant- 39 minutes for 1 epoch. This is the reason I could only run for 18 epochs. Only ten epochs are shown here but the weights for each epoch were saved to a file, only if there was improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5729BJGrU3H"
   },
   "source": [
    "# xi) Use the network with the best weights to generate 1000 characters, using the following text as initialization of the network:\n",
    "There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 17017
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 119045,
     "status": "ok",
     "timestamp": 1525291844007,
     "user": {
      "displayName": "Dab Berman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117214817576741121998"
     },
     "user_tz": 420
    },
    "id": "FB4CkPSeYXX7",
    "outputId": "4f53ed3e-1636-4403-a0e1-bd7e8e4c33ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n",
      "e\n",
      "a\n",
      "n\n",
      "d\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ",\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "f\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "i\n",
      "s\n",
      "a\n",
      "n\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "init_text = \"There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.\".lower()\n",
    "init_text=[char_ascii[char] for char in init_text]\n",
    "for i in range(1000):\n",
    "\tx1 = np.reshape(init_text, (1, len(init_text), 1))\n",
    "\tx1 = x1 / float(n_vocab)\n",
    "\tprediction = model.predict(x1, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = reverse_map[index]\n",
    "\tseq_in = [reverse_map[value] for value in init_text]\n",
    "\tprint(result)\n",
    "\tinit_text.append(index)\n",
    "\tinit_text = init_text[1:len(init_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fjc0a5l7euwq"
   },
   "source": [
    "#### Answer: As we can see Thousand characters were generated. Although the model still requires training as it  was run for 18 epochs only. The model started understanding the basic grammar and was able to use comma and period successfully."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "assignment-6-1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
